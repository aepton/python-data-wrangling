{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data wrangling\n",
    "\n",
    "### What we'll cover\n",
    "\n",
    "* Loading data\n",
    "* Transforming it\n",
    "* Storing it\n",
    "\n",
    "### How we'll do it\n",
    "\n",
    "We'll be working with a dataset, `contracts_data.csv`. It contains selected data on federal contracts from FY 2015 in Colorado. We'll use it to answer some real-life questions, with examples before each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from CSVs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `agate` library (formerly `csvkit` and `journalism`), by former Chicago Tribune developer Chris Groskopf, was built with journalists handling CSVs in mind ([here's the documentation](https://agate.readthedocs.org/)). The fundamental unit in `agate` is the table, and there's a one-step method of creating a table from a CSV file:\n",
    "\n",
    "    data = agate.Table.from_csv('data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn\n",
    "\n",
    "Load the data located in the `data/contracts_data.csv` file into an `agate` table and check out how the example works. Think about how you'd access a row's data. How would you answer a question like \"sum up all the values of a column in this spreadsheet?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--------------------------------------------------+---------------|\n",
      "|  column_names                                    | column_types  |\n",
      "|--------------------------------------------------+---------------|\n",
      "|  transaction_status                              | Text          |\n",
      "|  dollarsobligated                                | Number        |\n",
      "|  maj_fund_agency_cat                             | Date          |\n",
      "|  contractingofficeid                             | Text          |\n",
      "|  fundingrequestingofficeid                       | Text          |\n",
      "|  fundedbyforeignentity                           | Boolean       |\n",
      "|  signeddate                                      | Date          |\n",
      "|  effectivedate                                   | Date          |\n",
      "|  currentcompletiondate                           | Date          |\n",
      "|  ultimatecompletiondate                          | Date          |\n",
      "|  lastdatetoorder                                 | Boolean       |\n",
      "|  descriptionofcontractrequirement                | Text          |\n",
      "|  vendorname                                      | Text          |\n",
      "|  vendoralternatename                             | Text          |\n",
      "|  streetaddress                                   | Text          |\n",
      "|  streetaddress2                                  | Text          |\n",
      "|  streetaddress3                                  | Boolean       |\n",
      "|  city                                            | Text          |\n",
      "|  state                                           | Text          |\n",
      "|  zipcode                                         | Number        |\n",
      "|  vendorcountrycode                               | Text          |\n",
      "|  vendor_state_code                               | Text          |\n",
      "|  congressionaldistrict                           | Number        |\n",
      "|  dunsnumber                                      | Number        |\n",
      "|  parentdunsnumber                                | Number        |\n",
      "|  phoneno                                         | Number        |\n",
      "|  faxno                                           | Number        |\n",
      "|  registrationdate                                | Date          |\n",
      "|  renewaldate                                     | Date          |\n",
      "|  mod_parent                                      | Text          |\n",
      "|  statecode                                       | Text          |\n",
      "|  placeofperformancecity                          | Text          |\n",
      "|  pop_state_code                                  | Text          |\n",
      "|  placeofperformancecountrycode                   | Text          |\n",
      "|  placeofperformancezipcode                       | Number        |\n",
      "|  pop_cd                                          | Text          |\n",
      "|  placeofperformancecongressionaldistrict         | Text          |\n",
      "|  productorservicecode                            | Text          |\n",
      "|  fiscal_year                                     | Number        |\n",
      "|  extentcompeted                                  | Text          |\n",
      "|  reasonnotcompeted                               | Text          |\n",
      "|  numberofoffersreceived                          | Number        |\n",
      "|  solicitationprocedures                          | Text          |\n",
      "|  typeofsetaside                                  | Text          |\n",
      "|  localareasetaside                               | Boolean       |\n",
      "|  numberofemployees                               | Number        |\n",
      "|  annualrevenue                                   | Number        |\n",
      "|  issbacertifiedsmalldisadvantagedbusiness        | Boolean       |\n",
      "|  educationalinstitutionflag                      | Boolean       |\n",
      "|  womenownedflag                                  | Boolean       |\n",
      "|  veteranownedflag                                | Boolean       |\n",
      "|  minorityownedbusinessflag                       | Boolean       |\n",
      "|  tribalgovernmentflag                            | Boolean       |\n",
      "|  ishispanicservicinginstitution                  | Boolean       |\n",
      "|  iswomenownedsmallbusiness                       | Boolean       |\n",
      "|  isecondisadvwomenownedsmallbusiness             | Boolean       |\n",
      "|  isjointventurewomenownedsmallbusiness           | Boolean       |\n",
      "|  isjointventureecondisadvwomenownedsmallbusiness | Boolean       |\n",
      "|  walshhealyact                                   | Text          |\n",
      "|  servicecontractact                              | Text          |\n",
      "|  davisbaconact                                   | Text          |\n",
      "|  clingercohenact                                 | Boolean       |\n",
      "|  last_modified_date                              | Date          |\n",
      "|--------------------------------------------------+---------------|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import agate\n",
    "\n",
    "table = agate.Table.from_csv('data/contracts_data.csv') # Your loading code goes here\n",
    "\n",
    "print table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preview the data\n",
    "\n",
    "Now, let's preview a few of the records to see what the data that we are going to be working with looks like. For this by iterating over the rows in the table. To access the rows we interate over `table.rows`. Since this is a big file, we are going to return the first few rows by slicing (ie `[:3]`) `table.rows`.\n",
    "\n",
    "To get all the columns headers, we use `row.keys()` for the each row. Then we iterate over each of those and output the column header, and then the corresponding value through a lookup (i.e. `row[column]`).\n",
    "\n",
    "Finally, the last line of dashes (`--------------------`) is a visual output for us to easily identify where one record ends and the next one begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transaction_status: Active\n",
      "dollarsobligated: -3668.62\n",
      "maj_fund_agency_cat: 1200-01-01\n",
      "contractingofficeid: 4756: CHEROKEE NATIONAL FOREST\n",
      "fundingrequestingofficeid: 4756: CHEROKEE NATIONAL FOREST\n",
      "fundedbyforeignentity: None\n",
      "signeddate: 2014-11-13\n",
      "effectivedate: 2014-11-13\n",
      "currentcompletiondate: 2015-06-30\n",
      "ultimatecompletiondate: 2015-06-30\n",
      "lastdatetoorder: None\n",
      "descriptionofcontractrequirement: IGF::OT::IGF MOD TO CLOSE SOIL NAILING SERVICES FOR FSR#209 BRUSH CREEK ROAD\n",
      "vendorname: SOIL NAIL LAUNCHER, INC.\n",
      "vendoralternatename: None\n",
      "streetaddress: 543 31 RD\n",
      "streetaddress2: None\n",
      "streetaddress3: None\n",
      "city: GRAND JUNCTION\n",
      "state: CO\n",
      "zipcode: 815045772\n",
      "vendorcountrycode: UNITED STATES\n",
      "vendor_state_code: CO\n",
      "congressionaldistrict: 3\n",
      "dunsnumber: 137542788\n",
      "parentdunsnumber: 137542788\n",
      "phoneno: 9702106170\n",
      "faxno: 9702457737\n",
      "registrationdate: 2005-08-12\n",
      "renewaldate: 2009-06-19\n",
      "mod_parent: SOIL NAIL LAUNCHER  INC.\n",
      "statecode: TN: TENNESSEE\n",
      "placeofperformancecity: UNICOI\n",
      "pop_state_code: TN: TENNESSEE\n",
      "placeofperformancecountrycode: USA: UNITED STATES\n",
      "placeofperformancezipcode: 376926504\n",
      "pop_cd: TN01\n",
      "placeofperformancecongressionaldistrict: TN01\n",
      "productorservicecode: Z2LB: REPAIR OR ALTERATION OF HIGHWAYS/ROADS/STREETS/BRIDGES/RAILWAYS\n",
      "fiscal_year: 2015\n",
      "extentcompeted: A: FULL AND OPEN COMPETITION\n",
      "reasonnotcompeted: None\n",
      "numberofoffersreceived: 1\n",
      "solicitationprocedures: MAFO: SUBJECT TO MULTIPLE AWARD FAIR OPPORTUNITY\n",
      "typeofsetaside: NONE: NO SET ASIDE USED.\n",
      "localareasetaside: False\n",
      "numberofemployees: 8\n",
      "annualrevenue: 5000000\n",
      "issbacertifiedsmalldisadvantagedbusiness: True\n",
      "educationalinstitutionflag: False\n",
      "womenownedflag: False\n",
      "veteranownedflag: False\n",
      "minorityownedbusinessflag: False\n",
      "tribalgovernmentflag: False\n",
      "ishispanicservicinginstitution: False\n",
      "iswomenownedsmallbusiness: False\n",
      "isecondisadvwomenownedsmallbusiness: False\n",
      "isjointventurewomenownedsmallbusiness: False\n",
      "isjointventureecondisadvwomenownedsmallbusiness: False\n",
      "walshhealyact: X: Not Applicable\n",
      "servicecontractact: N\n",
      "davisbaconact: N\n",
      "clingercohenact: False\n",
      "last_modified_date: 2014-11-13\n",
      "--------------------------------------------------------------\n",
      "transaction_status: Active\n",
      "dollarsobligated: 9541.16\n",
      "maj_fund_agency_cat: 3600-01-01\n",
      "contractingofficeid: 00257: 257-NETWORK CONTRACT OFFICE 17\n",
      "fundingrequestingofficeid: 00671: 671-SAN ANTONIO\n",
      "fundedbyforeignentity: None\n",
      "signeddate: 2014-11-12\n",
      "effectivedate: 2014-11-12\n",
      "currentcompletiondate: 2014-11-28\n",
      "ultimatecompletiondate: 2014-11-28\n",
      "lastdatetoorder: None\n",
      "descriptionofcontractrequirement: IGF::OT::IGF, PREVENTIVE MAINTENACE FOR SPECTRANETICS LASER EXIMER MODEL CVX-300\n",
      "vendorname: SPECTRANETICS CORPORATION, THE\n",
      "vendoralternatename: None\n",
      "streetaddress: 9965 FEDERAL DR\n",
      "streetaddress2: None\n",
      "streetaddress3: None\n",
      "city: COLORADO SPRINGS\n",
      "state: CO\n",
      "zipcode: 809213617\n",
      "vendorcountrycode: UNITED STATES\n",
      "vendor_state_code: CO\n",
      "congressionaldistrict: 5\n",
      "dunsnumber: 151047370\n",
      "parentdunsnumber: 151047370\n",
      "phoneno: 7196338333\n",
      "faxno: 7194472091\n",
      "registrationdate: 2001-11-15\n",
      "renewaldate: 2015-06-27\n",
      "mod_parent: SPECTRANETICS CORPORATION\n",
      "statecode: TX: TEXAS\n",
      "placeofperformancecity: SAN ANTONIO\n",
      "pop_state_code: TX: TEXAS\n",
      "placeofperformancecountrycode: USA: UNITED STATES\n",
      "placeofperformancezipcode: 782294404\n",
      "pop_cd: TX21\n",
      "placeofperformancecongressionaldistrict: TX21\n",
      "productorservicecode: J065: MAINT/REPAIR/REBUILD OF EQUIPMENT- MEDICAL, DENTAL, AND VETERINARY EQUIPMENT AND SUPPLIES\n",
      "fiscal_year: 2015\n",
      "extentcompeted: C: NOT COMPETED\n",
      "reasonnotcompeted: ONE: ONLY ONE SOURCE - OTHER\n",
      "numberofoffersreceived: 1\n",
      "solicitationprocedures: SSS: ONLY ONE SOURCE\n",
      "typeofsetaside: NONE: NO SET ASIDE USED.\n",
      "localareasetaside: False\n",
      "numberofemployees: 600\n",
      "annualrevenue: 142000000\n",
      "issbacertifiedsmalldisadvantagedbusiness: False\n",
      "educationalinstitutionflag: False\n",
      "womenownedflag: False\n",
      "veteranownedflag: False\n",
      "minorityownedbusinessflag: False\n",
      "tribalgovernmentflag: False\n",
      "ishispanicservicinginstitution: False\n",
      "iswomenownedsmallbusiness: False\n",
      "isecondisadvwomenownedsmallbusiness: False\n",
      "isjointventurewomenownedsmallbusiness: False\n",
      "isjointventureecondisadvwomenownedsmallbusiness: False\n",
      "walshhealyact: N: No\n",
      "servicecontractact: N\n",
      "davisbaconact: X\n",
      "clingercohenact: False\n",
      "last_modified_date: 2014-11-18\n",
      "--------------------------------------------------------------\n",
      "transaction_status: Active\n",
      "dollarsobligated: 2380.65\n",
      "maj_fund_agency_cat: 1500-01-01\n",
      "contractingofficeid: 40303: ENGLEWOOD, FCI\n",
      "fundingrequestingofficeid: 40303: ENGLEWOOD, FCI\n",
      "fundedbyforeignentity: None\n",
      "signeddate: 2014-11-07\n",
      "effectivedate: 2014-11-07\n",
      "currentcompletiondate: 2014-12-07\n",
      "ultimatecompletiondate: 2014-12-07\n",
      "lastdatetoorder: None\n",
      "descriptionofcontractrequirement: WEEKLY PRODUCE ORDER\n",
      "vendorname: AMERICAN PRODUCE, LLC\n",
      "vendoralternatename: None\n",
      "streetaddress: 5151 BANNOCK ST STE 3\n",
      "streetaddress2: None\n",
      "streetaddress3: None\n",
      "city: DENVER\n",
      "state: CO\n",
      "zipcode: 802161846\n",
      "vendorcountrycode: UNITED STATES\n",
      "vendor_state_code: CO\n",
      "congressionaldistrict: 1\n",
      "dunsnumber: 40759438\n",
      "parentdunsnumber: 40759438\n",
      "phoneno: 3032910188\n",
      "faxno: 3032910219\n",
      "registrationdate: 2003-08-11\n",
      "renewaldate: 2015-05-08\n",
      "mod_parent: AMERICAN PRODUCE  LLC\n",
      "statecode: CO: COLORADO\n",
      "placeofperformancecity: DENVER\n",
      "pop_state_code: CO: COLORADO\n",
      "placeofperformancecountrycode: USA: UNITED STATES\n",
      "placeofperformancezipcode: 802161846\n",
      "pop_cd: CO01\n",
      "placeofperformancecongressionaldistrict: CO01\n",
      "productorservicecode: 8915: FRUITS AND VEGETABLES\n",
      "fiscal_year: 2015\n",
      "extentcompeted: G: NOT COMPETED UNDER SAP\n",
      "reasonnotcompeted: MPT: MICRO PURCHASE THRESHOLD\n",
      "numberofoffersreceived: 1\n",
      "solicitationprocedures: SP1: SIMPLIFIED ACQUISITION\n",
      "typeofsetaside: NONE: NO SET ASIDE USED.\n",
      "localareasetaside: False\n",
      "numberofemployees: 47\n",
      "annualrevenue: 18000000\n",
      "issbacertifiedsmalldisadvantagedbusiness: False\n",
      "educationalinstitutionflag: False\n",
      "womenownedflag: False\n",
      "veteranownedflag: False\n",
      "minorityownedbusinessflag: False\n",
      "tribalgovernmentflag: False\n",
      "ishispanicservicinginstitution: False\n",
      "iswomenownedsmallbusiness: False\n",
      "isecondisadvwomenownedsmallbusiness: False\n",
      "isjointventurewomenownedsmallbusiness: False\n",
      "isjointventureecondisadvwomenownedsmallbusiness: False\n",
      "walshhealyact: X: Not Applicable\n",
      "servicecontractact: X\n",
      "davisbaconact: X\n",
      "clingercohenact: False\n",
      "last_modified_date: 2014-11-07\n",
      "--------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for row in table.rows[:3]:\n",
    "    for column in row.keys():\n",
    "        print '%s: %s' % (column, row[column])\n",
    "    print '--------------------------------------------------------------'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to load CSVs\n",
    "\n",
    "It's worth mentioning that there's another way to load data from a CSV: `csv.DictReader`. \n",
    "\n",
    "**What is the difference between agate & csv libraries?**\n",
    "* csv is a part of core Python, which means there are no addition libraries to install\n",
    "* agate is built on top of csv and adds additional features to handling data\n",
    "* csv provides direct access to features such as writing csvs\n",
    "* agate handles a few of the processing elements in the background with the ability to override, while csv will sometimes require explicit arguments to be passed for a file to load\n",
    "* agate provides features for data wrangling, which is why we are using it\n",
    "\n",
    "Even though we are using agate, you should know how to import using the built-in csv library, because sometimes you just need to import a csv. To load a csv, we will use the `DictReader` method, which returns a list of dictionaries. Each dictionary is one row (or record) in the csv, with the header row (assuming there is one) converted into the dictionary's keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 lines\n"
     ]
    }
   ],
   "source": [
    "from csv import DictReader\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "with open('data/contracts_data.csv') as fh:\n",
    "    reader = DictReader(fh)\n",
    "    for row in reader:\n",
    "        # row is now a dict; each column in the CSV is a key in the dict\n",
    "        csv_data.append(row)\n",
    "\n",
    "print 'Found %d lines' % len(csv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `json` module includes two main methods: `loads` to load JSON data, and `dumps` to create JSON from Python objects. If you haven't worked with JSON before, it's a very convenient way of passing around data objects using pure text. \n",
    "\n",
    "`loads` just takes a single string of JSON-formatted data as an argument, and returns a Python object.\n",
    "\n",
    "    data = json.loads('{\"foo\":\"bar\"}')\n",
    "    print data['foo']\n",
    "\n",
    "displays `bar`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your turn\n",
    "\n",
    "Load the data located in the `data/contracts_data.json` file into a data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data from another sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XML, Excel, and other data formats\n",
    "There are mant different data formats that exist in the world. We are not going to cover them. Just know that there is a library almost all of them. For example to load XML, you might use (TODO), and to load Excel data, you would use (TODO).\n",
    "\n",
    "Sometimes libraries are clunky and horrible to use. For example, let's say you didn't like how the (TODO) library to import Excel data worked. If you didn't have a lot of sheets in your Excel workbook to export, a way around this is to export is manually to CSV first. Besides the manual route, there are a host of tools online and on the commandline that convert data formats from one to another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading from an API\n",
    "\n",
    "API stands for Application Programming Interface, but what does that mean? It is basically a end point available over the web for you to pick data up from. Before you try to gather data from an API by writing your own code, you should search for a library that does it for you. Larger, more well know APIs such as Twitter's API have multiple libraries in Python (TODO: Link to libraries). Somtimes these are written by the provider and sometimes by an outside party. \n",
    "\n",
    "If nothing exists, then use the requests library (TODO link) to hit the API end point to gather the data. The data will most likely be in one the formats already mentioned (i.e. JSON or CSV). Then you will save that locally and continue the loading process. \n",
    "\n",
    "Some APIs have keys and also sometimes tokens to limit how much the user can pull data from the API and possibly track their usage. While this isn't covered, you will need to add a few steps to account for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TODO Demo loading data from API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summing up a column of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geocoding addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the excellent library geopy ([docs](https://geopy.readthedocs.org/en/1.10.0/); run `pip install geopy` if you don't have it on your machine), which provides a common, simple interface to a variety of different geocoding services. It's worth noting that not all geocoding services work equally well, and they often have limits on how many requests you can make in a short amount of time. So if you're going to geocode a large number of addresses, you'll need to figure out which service is best for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an instance of a geocoder using a particular service, first import the appropriate class:\n",
    "\n",
    "    from geopy.geocoders import Nominatim\n",
    "\n",
    "Then create the instance:\n",
    "\n",
    "    geocoder = Nominatim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the geocoder instance created, using it is as simple as passing a string containing the address we're interested in:\n",
    "\n",
    "    location = geocoder.geocode(\"1701 California Street, Denver, CO\")\n",
    "\n",
    "And from there:\n",
    "\n",
    "    print location.latitude, location.longitude\n",
    "    \n",
    "Returns `39.7472023 -104.9904179`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn\n",
    "\n",
    "Create an instance of the Google geocoder, and use it to find the latitude and longitude of Molly Brown's house at 1340 Pennsylvania St in Denver **TODO: Should we make this more relevant to the story data?**. (Heads up: most geocoding services restrict heavy usage via IP addresses, so this classroom might get temporarily blocked and the examples may not work)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing dates and date strings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard `datetime` module and the excellent [strftime.org cheat sheet](http://www.strftime.org) (seriously, bookmark it) make Python able to translate between a really delicious variety of date and time formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To work with dates in our data, we first need to convert strings containing dates to actual date objects. To see why, let's ask the question: which of these dates comes first?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "older = '5-13-1989'\n",
    "newer = '2010-06-17'\n",
    "\n",
    "if older < newer:\n",
    "    print \"That's what I expect.\"\n",
    "else:\n",
    "    print \"Huh?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is because, when Python is comparing strings to each other (and both of the above dates, despite looking date-like, are just strings of text) it defaults to comparing them alphabetically. Does the first letter of string A come before the first letter of string B? If so, A < B.\n",
    "\n",
    "So, we need to tell Python how to convert our string of arbitrary text into a `datetime` object. Once we do that, we get all kinds of superpowers - we can add and subtract time from a date, compare dates to each other, adjust the timezone of our date, pull out just the month or year, determine what day of the week it was, and on and on.\n",
    "\n",
    "The `datetime` module provides several types of date-related classes we can use (in particular, `date`, `time` and `datetime`, which combines the first two) but for now we'll just rely on `datetime`. Annoyingly, `datetime` is both the name of a module, and the name of a class within that module, so we have to do dumb stuff like this:\n",
    "\n",
    "    from datetime import datetime\n",
    "\n",
    "Or\n",
    "\n",
    "    import datetime\n",
    "    datetime.datetime.now()\n",
    "\n",
    "I like the first one, myself. If we just wanted, say, `date` then we'd do:\n",
    "\n",
    "    from datetime import date\n",
    "\n",
    "Or\n",
    "\n",
    "    import datetime\n",
    "    datetime.date.today()\n",
    "\n",
    "Then we need to determine how to understand the date objects we're working with in our data (and this is where [strftime.org](http://www.strftime.org) is really useful). We do this by creating a format string, which tells datetime how our dates are structured.\n",
    "\n",
    "Take `older`, above. It's date is \"5-13-1989\": \"month hyphen day hyphen 4-digit year\". In the format string language that `datetime` uses, that translates to \"%m (month) hyphen %d (day) hyphen %Y (4-digit year)\". `datetime` expects that the format string will also tell it about any non-date characters, so we also have to include the hyphens in our format string. The end result will look like this:\n",
    "\n",
    "    format_string = '%m-%d-%Y'\n",
    "\n",
    "We then use the `strptime` function to create a `datetime` object from a string. We have to pass it both the string we'd like to convert, and the format string that tells us how to do so:\n",
    "\n",
    "    dt = datetime.strptime('5-13-1989', format_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Your turn\n",
    "\n",
    "Convert the dates below into `datetime` objects. For bonus points, try converting them into `date` objects. What did you have to do differently? When might one be preferred over the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "newer = '2010-06-17'\n",
    "two_digit_year = '1/20/00' # Now you see why Y2K seemed like a big deal (does anyone even remember Y2K?)\n",
    "crazy_text_having_variable = '2013 in June on day 12'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data as a CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data as JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `json` module makes it as easy to write JSON as it is to read it. However, since JSON is a very verbose format, it can make for very large files. The `contracts_data.csv` file, above, is 1.4 MB (enough to fit on a floppy!) - but the exact same data, stored in JSON, is over three times larger - 4.6 MB.\n",
    "\n",
    "So it's worth considering for a moment whether storing data in JSON is what you really want to do. It's great for Javascript web apps, for instance, because it's highly flexible and self-documenting, and therefore easy for programs to read it and work with it. But, particularly if your data has a large number of columns, the size of your JSON files can get very large very quickly (because every single row will repeat the name of every single column, plus 4 \" characters and a : character).\n",
    "\n",
    "Another thing to keep in mind is that some datatypes can't be represented in JSON. For instance, `datetime` objects need to be converted to strings first; you'll get an error if you try to save a `datetime` in JSON directly.\n",
    "\n",
    "The `dumps` method of the `json` module is the exact opposite of the `loads` method we used above, to load JSON data. Think of `dumps` as meaning, \"DUMP to String\" and `loads` as meaning, \"LOAD from String\". Here, we just want to write one gigantic string to a file, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/contracts_data.json', 'w+') as fh:\n",
    "    fh.write(json.dumps(csv_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving data to S3\n",
    "\n",
    "^^ This might be a little to advanced. Yes? No? (THat was my first impression) -jk (TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
